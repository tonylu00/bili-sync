---
title: "æŠ€æœ¯æ¶æ„æ–‡æ¡£"
description: "bili-sync v2.7.2 Final å®Œæ•´æŠ€æœ¯æ¶æ„å’Œè®¾è®¡ç†å¿µ"
---

# æŠ€æœ¯æ¶æ„æ–‡æ¡£

bili-sync v2.7.2 Final é‡‡ç”¨ç°ä»£åŒ–çš„æŠ€æœ¯æ¶æ„ï¼Œå®ç°äº†é«˜æ€§èƒ½ã€é«˜å¯é æ€§å’Œé«˜å¯æ‰©å±•æ€§çš„è®¾è®¡ç›®æ ‡ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»ç³»ç»Ÿçš„æŠ€æœ¯æ¶æ„ã€è®¾è®¡ç†å¿µå’Œæ ¸å¿ƒå®ç°ã€‚

## ğŸ—ï¸ æ•´ä½“æ¶æ„

### æ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "å‰ç«¯å±‚ (Frontend)"
        A[Svelte + TypeScript]
        B[Tailwind CSS]
        C[Web Components]
    end
    
    subgraph "APIå±‚ (API Layer)"
        D[Axum Web Framework]
        E[RESTful APIs]
        F[WebSocketå®æ—¶é€šä¿¡]
    end
    
    subgraph "ä¸šåŠ¡é€»è¾‘å±‚ (Business Logic)"
        G[æ™ºèƒ½é£æ§å¤„ç†]
        H[åŒé‡é‡ç½®ç³»ç»Ÿ]
        I[è§†é¢‘æºç®¡ç†]
        J[ä¸‹è½½è°ƒåº¦å™¨]
    end
    
    subgraph "æ•°æ®è®¿é—®å±‚ (Data Access)"
        K[SeaORM]
        L[SQLiteæ•°æ®åº“]
        M[æ•°æ®è¿ç§»ç³»ç»Ÿ]
    end
    
    subgraph "å¤–éƒ¨æœåŠ¡å±‚ (External Services)"
        N[å“”å“©å“”å“© API]
        O[Aria2ä¸‹è½½å™¨]
        P[FFmpegå¤„ç†]
    end
    
    A --> D
    B --> A
    C --> A
    D --> G
    D --> H
    D --> I
    G --> J
    H --> J
    I --> J
    J --> K
    K --> L
    K --> M
    J --> N
    J --> O
    J --> P
```

### æŠ€æœ¯æ ˆ

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | ç‰ˆæœ¬ | ç”¨é€” |
|------|----------|------|------|
| **å‰ç«¯æ¡†æ¶** | Svelte | 4.x | å“åº”å¼ç”¨æˆ·ç•Œé¢ |
| **å‰ç«¯è¯­è¨€** | TypeScript | 5.x | ç±»å‹å®‰å…¨çš„å‰ç«¯å¼€å‘ |
| **CSSæ¡†æ¶** | Tailwind CSS | 3.x | ç°ä»£åŒ–æ ·å¼è®¾è®¡ |
| **åç«¯æ¡†æ¶** | Axum | 0.7.x | é«˜æ€§èƒ½WebæœåŠ¡ |
| **åç«¯è¯­è¨€** | Rust | 1.75+ | ç³»ç»Ÿçº§æ€§èƒ½ä¸å®‰å…¨ |
| **å¼‚æ­¥è¿è¡Œæ—¶** | Tokio | 1.x | å¼‚æ­¥å¹¶å‘å¤„ç† |
| **ORMæ¡†æ¶** | SeaORM | 0.12.x | æ•°æ®åº“æŠ½è±¡å±‚ |
| **æ•°æ®åº“** | SQLite | 3.x | è½»é‡çº§æ•°æ®å­˜å‚¨ |
| **HTTPå®¢æˆ·ç«¯** | Reqwest | 0.11.x | HTTPè¯·æ±‚å¤„ç† |
| **ä¸‹è½½å™¨** | Aria2c | 1.x | å¤šçº¿ç¨‹ä¸‹è½½æ”¯æŒ |
| **åª’ä½“å¤„ç†** | FFmpeg | 6.x | éŸ³è§†é¢‘å¤„ç† |

## ğŸ¯ è®¾è®¡ç†å¿µ

### 1. æ™ºèƒ½åŒ–ä¼˜å…ˆ
- **è‡ªåŠ¨åŒ–å¤„ç†**ï¼šæœ€å°åŒ–ç”¨æˆ·å¹²é¢„ï¼Œç³»ç»Ÿè‡ªåŠ¨å¤„ç†å¤æ‚åœºæ™¯
- **æ™ºèƒ½å†³ç­–**ï¼šåŸºäºç®—æ³•çš„æ™ºèƒ½é€‰æ‹©å’Œä¼˜åŒ–
- **é¢„æµ‹æ€§ç»´æŠ¤**ï¼šä¸»åŠ¨å‘ç°å’Œè§£å†³æ½œåœ¨é—®é¢˜

### 2. é«˜æ€§èƒ½è®¾è®¡
- **å¼‚æ­¥å¹¶å‘**ï¼šTokioè¿è¡Œæ—¶æ”¯æŒé«˜å¹¶å‘æ“ä½œ
- **é›¶æ‹·è´ä¼˜åŒ–**ï¼šæœ€å°åŒ–å†…å­˜åˆ†é…å’Œæ•°æ®å¤åˆ¶
- **ç¼“å­˜ç­–ç•¥**ï¼šå¤šçº§ç¼“å­˜æå‡å“åº”é€Ÿåº¦

### 3. å¯é æ€§ä¿éšœ
- **é”™è¯¯æ¢å¤**ï¼šä¼˜é›…çš„é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨æ¢å¤æœºåˆ¶
- **æ•°æ®ä¸€è‡´æ€§**ï¼šäº‹åŠ¡ä¿è¯å’ŒçŠ¶æ€ç®¡ç†
- **å®¹é”™è®¾è®¡**ï¼šç³»ç»Ÿåœ¨å¼‚å¸¸æƒ…å†µä¸‹çš„ç¨³å®šè¿è¡Œ

### 4. å¯æ‰©å±•æ€§
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¸…æ™°çš„æ¨¡å—è¾¹ç•Œå’Œæ¥å£å®šä¹‰
- **æ’ä»¶æ¶æ„**ï¼šæ”¯æŒåŠŸèƒ½æ‰©å±•å’Œå®šåˆ¶
- **é…ç½®é©±åŠ¨**ï¼šçµæ´»çš„é…ç½®ç³»ç»Ÿ

## ğŸ§  æ ¸å¿ƒå­ç³»ç»Ÿ

### æ™ºèƒ½é£æ§å¤„ç†ç³»ç»Ÿ

#### æ¶æ„è®¾è®¡
```rust
// é£æ§æ£€æµ‹ä¸å¤„ç†æ¶æ„
pub struct RiskControlProcessor {
    detector: Arc<RiskControlDetector>,
    handler: Arc<RiskControlHandler>,
    recovery: Arc<AutoRecoverySystem>,
}

impl RiskControlProcessor {
    // å¤šå±‚æ£€æµ‹æœºåˆ¶
    pub async fn detect_risk_control(&self, error: &anyhow::Error) -> bool {
        // APIå±‚æ£€æµ‹
        if self.detector.check_api_error(error) { return true; }
        
        // ç½‘ç»œå±‚æ£€æµ‹
        if self.detector.check_network_error(error) { return true; }
        
        // ä¸šåŠ¡å±‚æ£€æµ‹
        if self.detector.check_business_error(error) { return true; }
        
        false
    }
    
    // æ™ºèƒ½å¤„ç†æµç¨‹
    pub async fn handle_risk_control(&self, connection: &DatabaseConnection) -> Result<()> {
        // 1. åœæ­¢å½“å‰æ‰€æœ‰ä»»åŠ¡
        self.handler.abort_all_tasks().await?;
        
        // 2. æ™ºèƒ½çŠ¶æ€åˆ†æ
        let analysis = self.handler.analyze_task_states(connection).await?;
        
        // 3. ç²¾ç¡®é‡ç½®ç­–ç•¥
        self.handler.apply_reset_strategy(analysis, connection).await?;
        
        // 4. å‡†å¤‡è‡ªåŠ¨æ¢å¤
        self.recovery.prepare_recovery().await?;
        
        Ok(())
    }
}
```

#### çŠ¶æ€ç®¡ç†ç®—æ³•
```rust
// æ™ºèƒ½çŠ¶æ€ä¿æŠ¤ç®—æ³•
pub fn intelligent_reset_strategy(tasks: &[TaskState]) -> ResetPlan {
    let mut plan = ResetPlan::new();
    
    for task in tasks {
        match task.status {
            TaskStatus::Completed(1) => {
                // æˆåŠŸå®Œæˆçš„ä»»åŠ¡ï¼Œä¿æŠ¤ä¸é‡ç½®
                plan.protect(task.id);
            },
            TaskStatus::InProgress(2) | TaskStatus::Failed(3) | TaskStatus::NotStarted(0) => {
                // æœªå®Œæˆçš„ä»»åŠ¡ï¼Œé‡ç½®ä¸ºåˆå§‹çŠ¶æ€
                plan.reset(task.id, TaskStatus::NotStarted(0));
            },
            _ => {
                // å…¶ä»–çŠ¶æ€æŒ‰å…·ä½“æƒ…å†µå¤„ç†
                plan.analyze(task);
            }
        }
    }
    
    plan
}
```

### åŒé‡é‡ç½®ç³»ç»Ÿ

#### ç³»ç»Ÿæ¶æ„
```rust
// åŒé‡é‡ç½®ç³»ç»Ÿè®¾è®¡
pub struct DualResetSystem {
    auto_reset: AutoResetProcessor,
    manual_reset: ManualResetProcessor,
    state_manager: StateManager,
}

// è‡ªåŠ¨é‡ç½®å¤„ç†å™¨
pub struct AutoResetProcessor {
    trigger_conditions: Vec<ResetTrigger>,
    reset_strategy: ResetStrategy,
}

// æ‰‹åŠ¨é‡ç½®å¤„ç†å™¨  
pub struct ManualResetProcessor {
    task_selector: TaskSelector,
    reset_validator: ResetValidator,
    confirmation_system: ConfirmationSystem,
}

impl DualResetSystem {
    // é£æ§è§¦å‘çš„è‡ªåŠ¨é‡ç½®
    pub async fn auto_reset_on_risk_control(&self, connection: &DatabaseConnection) -> Result<ResetResult> {
        let analysis = self.state_manager.analyze_all_tasks(connection).await?;
        let strategy = self.auto_reset.generate_strategy(analysis);
        self.auto_reset.execute_reset(strategy, connection).await
    }
    
    // ç”¨æˆ·ä¸»å¯¼çš„æ‰‹åŠ¨é‡ç½®
    pub async fn manual_reset(&self, request: ManualResetRequest, connection: &DatabaseConnection) -> Result<ResetResult> {
        // éªŒè¯é‡ç½®è¯·æ±‚
        self.manual_reset.reset_validator.validate(&request)?;
        
        // ç¡®è®¤æ“ä½œå®‰å…¨æ€§
        let confirmation = self.manual_reset.confirmation_system.confirm(&request).await?;
        
        // æ‰§è¡Œç²¾ç¡®é‡ç½®
        self.manual_reset.execute_precise_reset(request, connection).await
    }
}
```

#### ä»»åŠ¡çŠ¶æ€æœº
```rust
// ä»»åŠ¡çŠ¶æ€è½¬æ¢æœºåˆ¶
#[derive(Debug, Clone, Copy)]
pub enum TaskStatus {
    NotStarted = 0,     // æœªå¼€å§‹
    Completed = 1,      // æˆåŠŸå®Œæˆ
    InProgress = 2,     // è¿›è¡Œä¸­/å¤±è´¥2æ¬¡
    Failed = 3,         // å¤±è´¥3æ¬¡
    FinalSuccess = 7,   // æœ€ç»ˆæˆåŠŸçŠ¶æ€
}

impl TaskStatus {
    // çŠ¶æ€è½¬æ¢è§„åˆ™
    pub fn can_reset(&self) -> bool {
        match self {
            TaskStatus::Completed | TaskStatus::FinalSuccess => false, // ä¿æŠ¤å·²å®Œæˆ
            _ => true, // å…¶ä»–çŠ¶æ€å¯ä»¥é‡ç½®
        }
    }
    
    // æ™ºèƒ½é‡ç½®ç›®æ ‡
    pub fn reset_target(&self) -> TaskStatus {
        TaskStatus::NotStarted
    }
}
```

### è§†é¢‘æºç®¡ç†ç³»ç»Ÿ

#### ç»Ÿä¸€æŠ½è±¡æ¥å£
```rust
// è§†é¢‘æºç»Ÿä¸€æŠ½è±¡
#[async_trait]
pub trait VideoSource {
    type Item: VideoItem;
    
    async fn fetch_videos(&self, page: u32) -> Result<Vec<Self::Item>>;
    async fn get_latest_update_time(&self) -> Result<DateTime<Utc>>;
    async fn validate_source(&self) -> Result<bool>;
    
    // å¯ç”¨/ç¦ç”¨çŠ¶æ€ç®¡ç†
    fn is_enabled(&self) -> bool;
    async fn set_enabled(&mut self, enabled: bool) -> Result<()>;
}

// å…·ä½“å®ç°
pub struct FavoriteSource {
    fid: String,
    enabled: bool,
    last_update: Option<DateTime<Utc>>,
}

pub struct SubmissionSource {
    upper_id: String,
    enabled: bool,
    last_update: Option<DateTime<Utc>>,
}

pub struct BangumiSource {
    season_id: String,
    download_all_seasons: bool,
    selected_seasons: Option<Vec<String>>,
    enabled: bool,
}
```

#### åŠ¨æ€è°ƒåº¦å™¨
```rust
// æ™ºèƒ½è§†é¢‘æºè°ƒåº¦
pub struct VideoSourceScheduler {
    sources: Arc<RwLock<Vec<Box<dyn VideoSource + Send + Sync>>>>,
    scheduler: Arc<TaskScheduler>,
}

impl VideoSourceScheduler {
    // åªå¤„ç†å¯ç”¨çš„è§†é¢‘æº
    pub async fn scan_enabled_sources(&self) -> Result<ScanResult> {
        let sources = self.sources.read().await;
        let enabled_sources: Vec<_> = sources
            .iter()
            .filter(|source| source.is_enabled())
            .collect();
            
        info!("å¼€å§‹æ‰«æ {} ä¸ªå¯ç”¨çš„è§†é¢‘æº", enabled_sources.len());
        
        let mut results = Vec::new();
        for source in enabled_sources {
            if let Ok(result) = self.scan_single_source(source).await {
                results.push(result);
            }
        }
        
        Ok(ScanResult::new(results))
    }
}
```

### ä¸‹è½½è°ƒåº¦ç³»ç»Ÿ

#### å¤šçº§è°ƒåº¦æ¶æ„
```rust
// åˆ†å±‚ä¸‹è½½è°ƒåº¦
pub struct DownloadScheduler {
    video_scheduler: VideoScheduler,
    page_scheduler: PageScheduler,
    resource_manager: ResourceManager,
    concurrency_limiter: ConcurrencyLimiter,
}

// å¹¶å‘æ§åˆ¶
pub struct ConcurrencyLimiter {
    video_semaphore: Arc<Semaphore>,
    page_semaphore: Arc<Semaphore>,
    network_semaphore: Arc<Semaphore>,
}

impl DownloadScheduler {
    // æ™ºèƒ½èµ„æºåˆ†é…
    pub async fn schedule_downloads(&self, videos: Vec<VideoTask>) -> Result<()> {
        let video_semaphore = &self.concurrency_limiter.video_semaphore;
        
        let tasks = videos.into_iter().map(|video| {
            let semaphore = video_semaphore.clone();
            let scheduler = self.clone();
            
            async move {
                let _permit = semaphore.acquire().await?;
                scheduler.process_video(video).await
            }
        });
        
        // å¹¶å‘æ‰§è¡Œï¼Œæ™ºèƒ½é”™è¯¯å¤„ç†
        futures::future::try_join_all(tasks).await?;
        Ok(())
    }
    
    // è‡ªé€‚åº”é‡è¯•æœºåˆ¶
    pub async fn adaptive_retry<F, T>(&self, operation: F, max_retries: u32) -> Result<T>
    where
        F: Fn() -> Pin<Box<dyn Future<Output = Result<T>> + Send>> + Send + Sync,
    {
        let mut attempts = 0;
        loop {
            match operation().await {
                Ok(result) => return Ok(result),
                Err(e) if attempts < max_retries => {
                    let delay = self.calculate_backoff_delay(attempts);
                    tokio::time::sleep(delay).await;
                    attempts += 1;
                }
                Err(e) => return Err(e),
            }
        }
    }
}
```

## ğŸ—„ï¸ æ•°æ®æ¶æ„

### æ•°æ®åº“è®¾è®¡

#### æ ¸å¿ƒå®ä½“å…³ç³»
```mermaid
erDiagram
    VideoSource ||--o{ Video : "produces"
    Video ||--o{ Page : "contains"
    Video {
        int id PK
        string bvid
        string name
        string cover
        int source_type
        boolean enabled
        datetime created_at
        u32 download_status
    }
    
    Page {
        int id PK
        int video_id FK
        int pid
        string name
        int cid
        int duration
        u32 download_status
        string path
    }
    
    Favorite {
        int id PK
        string f_id
        string name
        string path
        boolean enabled
        datetime latest_row_at
    }
    
    Submission {
        int id PK
        string upper_id
        string name
        string path
        boolean enabled
        datetime latest_row_at
    }
    
    Collection {
        int id PK
        string m_id
        string s_id
        int type
        string name
        string path
        boolean enabled
    }
```

#### æ€§èƒ½ä¼˜åŒ–ç´¢å¼•
```sql
-- å…³é”®æŸ¥è¯¢ç´¢å¼•
CREATE INDEX idx_video_source_enabled ON video(source_type, enabled);
CREATE INDEX idx_video_download_status ON video(download_status);
CREATE INDEX idx_page_video_status ON page(video_id, download_status);
CREATE INDEX idx_favorite_enabled ON favorite(enabled);
CREATE INDEX idx_submission_enabled ON submission(enabled);
CREATE INDEX idx_collection_enabled ON collection(enabled);

-- å¤åˆç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_video_source_time ON video(source_type, enabled, created_at);
CREATE INDEX idx_page_video_download ON page(video_id, download_status, pid);
```

### æ•°æ®è¿ç§»ç³»ç»Ÿ

#### ç‰ˆæœ¬åŒ–è¿ç§»
```rust
// æ•°æ®åº“è¿ç§»ç®¡ç†
pub struct MigrationManager {
    migrations: Vec<Box<dyn Migration>>,
    current_version: u32,
}

#[async_trait]
pub trait Migration {
    fn version(&self) -> u32;
    fn description(&self) -> &str;
    async fn up(&self, connection: &DatabaseConnection) -> Result<()>;
    async fn down(&self, connection: &DatabaseConnection) -> Result<()>;
}

// v2.7.2 Final æ–°å¢è¿ç§»
pub struct AddEnabledFieldMigration;

#[async_trait]
impl Migration for AddEnabledFieldMigration {
    fn version(&self) -> u32 { 20250613_000002 }
    
    fn description(&self) -> &str {
        "Add enabled field to all video source tables"
    }
    
    async fn up(&self, connection: &DatabaseConnection) -> Result<()> {
        // ä¸ºæ‰€æœ‰è§†é¢‘æºè¡¨æ·»åŠ enabledå­—æ®µ
        let sqls = vec![
            "ALTER TABLE favorite ADD COLUMN enabled BOOLEAN DEFAULT true",
            "ALTER TABLE submission ADD COLUMN enabled BOOLEAN DEFAULT true", 
            "ALTER TABLE collection ADD COLUMN enabled BOOLEAN DEFAULT true",
            "ALTER TABLE watch_later ADD COLUMN enabled BOOLEAN DEFAULT true",
            "ALTER TABLE video_source ADD COLUMN enabled BOOLEAN DEFAULT true",
        ];
        
        for sql in sqls {
            connection.execute_unprepared(sql).await?;
        }
        
        Ok(())
    }
}
```

## ğŸŒ ç½‘ç»œæ¶æ„

### HTTPæœåŠ¡è®¾è®¡

#### Axumè·¯ç”±æ¶æ„
```rust
// RESTful API è·¯ç”±è®¾è®¡
pub fn create_app() -> Router {
    Router::new()
        // è§†é¢‘æºç®¡ç†
        .nest("/api/sources", source_routes())
        // è§†é¢‘ç®¡ç†
        .nest("/api/videos", video_routes())
        // é‡ç½®ç³»ç»Ÿ
        .nest("/api/reset", reset_routes())
        // ç³»ç»Ÿç®¡ç†
        .nest("/api/system", system_routes())
        // å›¾ç‰‡ä»£ç†
        .route("/api/proxy/image", get(proxy_image))
        // WebSocketå®æ—¶é€šä¿¡
        .route("/ws", get(websocket_handler))
        // é™æ€æ–‡ä»¶æœåŠ¡
        .nest_service("/", ServeDir::new("./web/dist"))
        // ä¸­é—´ä»¶
        .layer(cors_layer())
        .layer(auth_layer())
        .layer(logging_layer())
}

// åˆ†æ¨¡å—è·¯ç”±
fn video_routes() -> Router {
    Router::new()
        .route("/", get(list_videos).post(create_video))
        .route("/:id", get(get_video).put(update_video).delete(delete_video))
        .route("/reset", post(reset_videos))
        .route("/reset-specific-tasks", post(reset_specific_tasks))
        .route("/:id/pages", get(list_pages))
}
```

#### ä¸­é—´ä»¶ç³»ç»Ÿ
```rust
// è®¤è¯ä¸­é—´ä»¶
pub async fn auth_middleware(
    req: Request<Body>,
    next: Next<Body>,
) -> Result<Response, StatusCode> {
    let auth_header = req.headers().get("Authorization");
    
    if let Some(token) = auth_header.and_then(|h| h.to_str().ok()) {
        if validate_token(token).await? {
            return Ok(next.run(req).await);
        }
    }
    
    Err(StatusCode::UNAUTHORIZED)
}

// é”™è¯¯å¤„ç†ä¸­é—´ä»¶
pub async fn error_handling_middleware(
    req: Request<Body>,
    next: Next<Body>,
) -> Response {
    match next.run(req).await {
        response => {
            if response.status().is_server_error() {
                // è®°å½•é”™è¯¯æ—¥å¿—
                error!("Server error: {:?}", response);
                
                // è¿”å›æ ‡å‡†åŒ–é”™è¯¯å“åº”
                create_error_response(response.status(), "Internal server error")
            } else {
                response
            }
        }
    }
}
```

### WebSocketå®æ—¶é€šä¿¡

#### å®æ—¶äº‹ä»¶ç³»ç»Ÿ
```rust
// WebSocketäº‹ä»¶ç³»ç»Ÿ
pub struct WebSocketManager {
    connections: Arc<RwLock<HashMap<Uuid, WebSocketConnection>>>,
    event_bus: Arc<EventBus>,
}

#[derive(Debug, Clone, Serialize)]
pub enum SystemEvent {
    DownloadProgress { video_id: i32, progress: f64 },
    VideoAdded { video: VideoModel },
    VideoDeleted { video_id: i32 },
    RiskControlDetected { message: String },
    ResetCompleted { reset_type: ResetType, count: u32 },
    SourceStatusChanged { source_id: i32, enabled: bool },
}

impl WebSocketManager {
    // å¹¿æ’­ç³»ç»Ÿäº‹ä»¶
    pub async fn broadcast_event(&self, event: SystemEvent) {
        let connections = self.connections.read().await;
        let message = serde_json::to_string(&event).unwrap();
        
        for connection in connections.values() {
            if let Err(e) = connection.send(message.clone()).await {
                warn!("Failed to send WebSocket message: {}", e);
            }
        }
    }
    
    // å¤„ç†å®¢æˆ·ç«¯è¿æ¥
    pub async fn handle_connection(&self, socket: WebSocket) {
        let (sender, mut receiver) = socket.split();
        let connection_id = Uuid::new_v4();
        
        // æ³¨å†Œè¿æ¥
        {
            let mut connections = self.connections.write().await;
            connections.insert(connection_id, WebSocketConnection::new(sender));
        }
        
        // å¤„ç†æ¶ˆæ¯
        while let Some(msg) = receiver.next().await {
            match msg {
                Ok(Message::Text(text)) => {
                    if let Ok(command) = serde_json::from_str::<ClientCommand>(&text) {
                        self.handle_client_command(command).await;
                    }
                }
                Ok(Message::Close(_)) => break,
                Err(e) => {
                    error!("WebSocket error: {}", e);
                    break;
                }
                _ => {}
            }
        }
        
        // æ¸…ç†è¿æ¥
        {
            let mut connections = self.connections.write().await;
            connections.remove(&connection_id);
        }
    }
}
```

## ğŸ”’ å®‰å…¨æ¶æ„

### è®¤è¯ä¸æˆæƒ

#### Tokenè®¤è¯ç³»ç»Ÿ
```rust
// JWT Tokenç®¡ç†
pub struct TokenManager {
    secret_key: Vec<u8>,
    token_duration: Duration,
}

impl TokenManager {
    // ç”Ÿæˆè®¿é—®ä»¤ç‰Œ
    pub fn generate_token(&self, user_id: &str) -> Result<String> {
        let claims = Claims {
            sub: user_id.to_string(),
            exp: (Utc::now() + self.token_duration).timestamp() as usize,
            iat: Utc::now().timestamp() as usize,
        };
        
        encode(&Header::default(), &claims, &EncodingKey::from_secret(&self.secret_key))
            .map_err(|e| anyhow!("Token generation failed: {}", e))
    }
    
    // éªŒè¯ä»¤ç‰Œ
    pub fn validate_token(&self, token: &str) -> Result<Claims> {
        decode::<Claims>(
            token,
            &DecodingKey::from_secret(&self.secret_key),
            &Validation::default(),
        )
        .map(|token_data| token_data.claims)
        .map_err(|e| anyhow!("Token validation failed: {}", e))
    }
}
```

#### æƒé™æ§åˆ¶
```rust
// åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶
#[derive(Debug, Clone)]
pub enum Permission {
    ReadVideos,
    WriteVideos,
    DeleteVideos,
    ManageSources,
    SystemConfig,
    ResetTasks,
}

#[derive(Debug, Clone)]
pub enum Role {
    Viewer,
    Editor,
    Admin,
}

impl Role {
    pub fn permissions(&self) -> Vec<Permission> {
        match self {
            Role::Viewer => vec![Permission::ReadVideos],
            Role::Editor => vec![
                Permission::ReadVideos,
                Permission::WriteVideos,
                Permission::ManageSources,
            ],
            Role::Admin => vec![
                Permission::ReadVideos,
                Permission::WriteVideos,
                Permission::DeleteVideos,
                Permission::ManageSources,
                Permission::SystemConfig,
                Permission::ResetTasks,
            ],
        }
    }
}
```

### æ•°æ®å®‰å…¨

#### æ•æ„Ÿæ•°æ®ä¿æŠ¤
```rust
// æ•æ„Ÿé…ç½®åŠ å¯†
pub struct SecretManager {
    encryption_key: [u8; 32],
}

impl SecretManager {
    // åŠ å¯†æ•æ„Ÿé…ç½®
    pub fn encrypt_config(&self, config: &str) -> Result<String> {
        let cipher = ChaCha20Poly1305::new(GenericArray::from_slice(&self.encryption_key));
        let nonce = ChaCha20Poly1305::generate_nonce(&mut OsRng);
        
        let ciphertext = cipher
            .encrypt(&nonce, config.as_bytes())
            .map_err(|e| anyhow!("Encryption failed: {}", e))?;
        
        let mut result = nonce.to_vec();
        result.extend(ciphertext);
        
        Ok(base64::encode(result))
    }
    
    // è§£å¯†æ•æ„Ÿé…ç½®
    pub fn decrypt_config(&self, encrypted: &str) -> Result<String> {
        let data = base64::decode(encrypted)?;
        let (nonce_bytes, ciphertext) = data.split_at(12);
        
        let cipher = ChaCha20Poly1305::new(GenericArray::from_slice(&self.encryption_key));
        let nonce = GenericArray::from_slice(nonce_bytes);
        
        let plaintext = cipher
            .decrypt(nonce, ciphertext)
            .map_err(|e| anyhow!("Decryption failed: {}", e))?;
        
        String::from_utf8(plaintext).map_err(|e| anyhow!("Invalid UTF-8: {}", e))
    }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å¼‚æ­¥å¹¶å‘ä¼˜åŒ–

#### æ™ºèƒ½å¹¶å‘æ§åˆ¶
```rust
// è‡ªé€‚åº”å¹¶å‘æ§åˆ¶
pub struct AdaptiveConcurrencyLimiter {
    video_limit: Arc<AtomicUsize>,
    page_limit: Arc<AtomicUsize>,
    success_rate: Arc<AtomicU64>,
    adjustment_interval: Duration,
}

impl AdaptiveConcurrencyLimiter {
    // åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
    pub async fn adjust_concurrency(&self) {
        let current_success_rate = self.get_success_rate();
        
        match current_success_rate {
            rate if rate > 0.95 => {
                // æˆåŠŸç‡é«˜ï¼Œå¯ä»¥æå‡å¹¶å‘
                self.increase_concurrency().await;
            }
            rate if rate < 0.80 => {
                // æˆåŠŸç‡ä½ï¼Œé™ä½å¹¶å‘
                self.decrease_concurrency().await;
            }
            _ => {
                // æˆåŠŸç‡é€‚ä¸­ï¼Œä¿æŒå½“å‰è®¾ç½®
            }
        }
    }
    
    // è·å–å½“å‰æœ€ä½³å¹¶å‘æ•°
    pub async fn acquire_video_permit(&self) -> Result<SemaphorePermit> {
        let current_limit = self.video_limit.load(Ordering::Relaxed);
        let semaphore = Semaphore::new(current_limit);
        semaphore.acquire().await.map_err(|e| anyhow!("Failed to acquire permit: {}", e))
    }
}
```

### å†…å­˜ä¼˜åŒ–

#### é›¶æ‹·è´æ•°æ®å¤„ç†
```rust
// é›¶æ‹·è´æ–‡ä»¶å¤„ç†
pub struct ZeroCopyFileHandler;

impl ZeroCopyFileHandler {
    // ä½¿ç”¨å†…å­˜æ˜ å°„è¿›è¡Œå¤§æ–‡ä»¶å¤„ç†
    pub async fn process_large_file<F>(path: &Path, processor: F) -> Result<()>
    where
        F: Fn(&[u8]) -> Result<()>,
    {
        let file = File::open(path).await?;
        let mmap = unsafe { MmapOptions::new().map(&file)? };
        
        // åˆ†å—å¤„ç†ï¼Œé¿å…å¤§é‡å†…å­˜åˆ†é…
        const CHUNK_SIZE: usize = 64 * 1024; // 64KB chunks
        
        for chunk in mmap.chunks(CHUNK_SIZE) {
            processor(chunk)?;
        }
        
        Ok(())
    }
    
    // æµå¼æ•°æ®ä¼ è¾“
    pub async fn stream_download(url: &str, path: &Path) -> Result<()> {
        let response = reqwest::get(url).await?;
        let mut file = File::create(path).await?;
        let mut stream = response.bytes_stream();
        
        while let Some(chunk) = stream.next().await {
            let chunk = chunk?;
            file.write_all(&chunk).await?;
        }
        
        file.flush().await?;
        Ok(())
    }
}
```

### ç¼“å­˜ç³»ç»Ÿ

#### å¤šçº§ç¼“å­˜æ¶æ„
```rust
// å¤šçº§ç¼“å­˜ç³»ç»Ÿ
pub struct MultiLevelCache {
    l1_cache: Arc<RwLock<LruCache<String, Arc<CacheEntry>>>>, // å†…å­˜ç¼“å­˜
    l2_cache: Arc<DiskCache>,                                  // ç£ç›˜ç¼“å­˜
    l3_cache: Arc<DatabaseCache>,                             // æ•°æ®åº“ç¼“å­˜
}

impl MultiLevelCache {
    // æ™ºèƒ½ç¼“å­˜è·å–
    pub async fn get<T: DeserializeOwned>(&self, key: &str) -> Option<T> {
        // L1: å†…å­˜ç¼“å­˜
        if let Some(entry) = self.l1_cache.read().await.get(key) {
            if !entry.is_expired() {
                return entry.value::<T>().ok();
            }
        }
        
        // L2: ç£ç›˜ç¼“å­˜
        if let Ok(Some(value)) = self.l2_cache.get(key).await {
            // å›å¡«L1ç¼“å­˜
            self.l1_cache.write().await.put(key.to_string(), Arc::new(CacheEntry::new(value.clone())));
            return Some(value);
        }
        
        // L3: æ•°æ®åº“ç¼“å­˜
        if let Ok(Some(value)) = self.l3_cache.get(key).await {
            // å›å¡«ä¸Šçº§ç¼“å­˜
            self.l2_cache.put(key, &value).await.ok();
            self.l1_cache.write().await.put(key.to_string(), Arc::new(CacheEntry::new(value.clone())));
            return Some(value);
        }
        
        None
    }
    
    // æ™ºèƒ½ç¼“å­˜æ›´æ–°
    pub async fn put<T: Serialize>(&self, key: &str, value: T, ttl: Duration) -> Result<()> {
        let entry = Arc::new(CacheEntry::with_ttl(value, ttl));
        
        // åŒæ—¶æ›´æ–°æ‰€æœ‰ç¼“å­˜å±‚
        self.l1_cache.write().await.put(key.to_string(), entry.clone());
        self.l2_cache.put(key, &entry.value).await?;
        self.l3_cache.put(key, &entry.value).await?;
        
        Ok(())
    }
}
```

## ğŸ“Š ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### æŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ

#### æ€§èƒ½æŒ‡æ ‡ç›‘æ§
```rust
// ç³»ç»ŸæŒ‡æ ‡æ”¶é›†
pub struct MetricsCollector {
    download_metrics: Arc<DownloadMetrics>,
    system_metrics: Arc<SystemMetrics>,
    business_metrics: Arc<BusinessMetrics>,
}

#[derive(Debug, Clone)]
pub struct DownloadMetrics {
    pub total_downloads: AtomicU64,
    pub successful_downloads: AtomicU64,
    pub failed_downloads: AtomicU64,
    pub average_speed: AtomicU64, // bytes per second
    pub current_active_downloads: AtomicUsize,
}

impl MetricsCollector {
    // è®°å½•ä¸‹è½½äº‹ä»¶
    pub fn record_download_event(&self, event: DownloadEvent) {
        match event {
            DownloadEvent::Started { .. } => {
                self.download_metrics.current_active_downloads.fetch_add(1, Ordering::Relaxed);
            }
            DownloadEvent::Completed { size, duration } => {
                self.download_metrics.successful_downloads.fetch_add(1, Ordering::Relaxed);
                self.download_metrics.current_active_downloads.fetch_sub(1, Ordering::Relaxed);
                
                let speed = size as f64 / duration.as_secs_f64();
                self.update_average_speed(speed as u64);
            }
            DownloadEvent::Failed { .. } => {
                self.download_metrics.failed_downloads.fetch_add(1, Ordering::Relaxed);
                self.download_metrics.current_active_downloads.fetch_sub(1, Ordering::Relaxed);
            }
        }
    }
    
    // ç”ŸæˆæŒ‡æ ‡æŠ¥å‘Š
    pub fn generate_metrics_report(&self) -> MetricsReport {
        MetricsReport {
            download_success_rate: self.calculate_success_rate(),
            average_download_speed: self.download_metrics.average_speed.load(Ordering::Relaxed),
            active_downloads: self.download_metrics.current_active_downloads.load(Ordering::Relaxed),
            system_load: self.system_metrics.get_current_load(),
            memory_usage: self.system_metrics.get_memory_usage(),
            disk_usage: self.system_metrics.get_disk_usage(),
        }
    }
}
```

### æ—¥å¿—ç³»ç»Ÿ

#### ç»“æ„åŒ–æ—¥å¿—
```rust
// ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ
pub struct StructuredLogger {
    inner: Arc<dyn Logger>,
    context: Arc<RwLock<LogContext>>,
}

#[derive(Debug, Clone, Serialize)]
pub struct LogEntry {
    pub timestamp: DateTime<Utc>,
    pub level: LogLevel,
    pub module: String,
    pub message: String,
    pub fields: HashMap<String, serde_json::Value>,
    pub trace_id: Option<String>,
}

impl StructuredLogger {
    // è®°å½•ä¸šåŠ¡äº‹ä»¶
    pub async fn log_business_event(&self, event: BusinessEvent) {
        let entry = LogEntry {
            timestamp: Utc::now(),
            level: LogLevel::Info,
            module: "business".to_string(),
            message: event.description(),
            fields: event.to_fields(),
            trace_id: self.get_current_trace_id().await,
        };
        
        self.inner.log(entry).await;
    }
    
    // è®°å½•æ€§èƒ½äº‹ä»¶
    pub async fn log_performance_event(&self, operation: &str, duration: Duration, success: bool) {
        let mut fields = HashMap::new();
        fields.insert("operation".to_string(), json!(operation));
        fields.insert("duration_ms".to_string(), json!(duration.as_millis()));
        fields.insert("success".to_string(), json!(success));
        
        let entry = LogEntry {
            timestamp: Utc::now(),
            level: if success { LogLevel::Info } else { LogLevel::Warn },
            module: "performance".to_string(),
            message: format!("Operation {} completed in {}ms", operation, duration.as_millis()),
            fields,
            trace_id: self.get_current_trace_id().await,
        };
        
        self.inner.log(entry).await;
    }
}
```

## ğŸ”® æ‰©å±•æ€§è®¾è®¡

### æ’ä»¶ç³»ç»Ÿæ¶æ„

#### æ’ä»¶æ¥å£å®šä¹‰
```rust
// æ’ä»¶ç³»ç»Ÿæ¥å£
#[async_trait]
pub trait Plugin: Send + Sync {
    fn name(&self) -> &str;
    fn version(&self) -> &str;
    
    async fn initialize(&mut self, context: PluginContext) -> Result<()>;
    async fn shutdown(&mut self) -> Result<()>;
    
    // ç”Ÿå‘½å‘¨æœŸé’©å­
    async fn on_video_added(&self, video: &VideoModel) -> Result<()> { Ok(()) }
    async fn on_video_downloaded(&self, video: &VideoModel) -> Result<()> { Ok(()) }
    async fn on_download_failed(&self, video: &VideoModel, error: &anyhow::Error) -> Result<()> { Ok(()) }
    
    // è‡ªå®šä¹‰å¤„ç†å™¨
    async fn process_custom_event(&self, event: CustomEvent) -> Result<Option<CustomResponse>> { 
        Ok(None) 
    }
}

// æ’ä»¶ç®¡ç†å™¨
pub struct PluginManager {
    plugins: Arc<RwLock<HashMap<String, Box<dyn Plugin>>>>,
    event_bus: Arc<EventBus>,
}

impl PluginManager {
    // æ³¨å†Œæ’ä»¶
    pub async fn register_plugin(&self, plugin: Box<dyn Plugin>) -> Result<()> {
        let name = plugin.name().to_string();
        
        // åˆå§‹åŒ–æ’ä»¶
        let mut plugin = plugin;
        plugin.initialize(self.create_plugin_context()).await?;
        
        // æ³¨å†Œäº‹ä»¶ç›‘å¬
        self.register_plugin_events(&name).await?;
        
        // å­˜å‚¨æ’ä»¶
        self.plugins.write().await.insert(name.clone(), plugin);
        
        info!("Plugin '{}' registered successfully", name);
        Ok(())
    }
    
    // è§¦å‘æ’ä»¶äº‹ä»¶
    pub async fn trigger_event(&self, event: PluginEvent) -> Result<()> {
        let plugins = self.plugins.read().await;
        
        for plugin in plugins.values() {
            match &event {
                PluginEvent::VideoAdded(video) => {
                    if let Err(e) = plugin.on_video_added(video).await {
                        warn!("Plugin '{}' failed to handle video_added event: {}", plugin.name(), e);
                    }
                }
                PluginEvent::VideoDownloaded(video) => {
                    if let Err(e) = plugin.on_video_downloaded(video).await {
                        warn!("Plugin '{}' failed to handle video_downloaded event: {}", plugin.name(), e);
                    }
                }
                PluginEvent::DownloadFailed(video, error) => {
                    if let Err(e) = plugin.on_download_failed(video, error).await {
                        warn!("Plugin '{}' failed to handle download_failed event: {}", plugin.name(), e);
                    }
                }
            }
        }
        
        Ok(())
    }
}
```

## ğŸ“‹ æ€»ç»“

bili-sync v2.7.2 Final çš„æŠ€æœ¯æ¶æ„ä»£è¡¨äº†ç°ä»£åŒ–ç³»ç»Ÿè®¾è®¡çš„æœ€ä½³å®è·µï¼š

### ğŸ¯ æ¶æ„ä¼˜åŠ¿

**ğŸ¤– æ™ºèƒ½åŒ–è®¾è®¡**ï¼š
- è‡ªåŠ¨é£æ§å¤„ç†å’Œæ¢å¤æœºåˆ¶
- æ™ºèƒ½å¹¶å‘æ§åˆ¶å’Œèµ„æºåˆ†é…
- è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–ç®—æ³•

**âš¡ é«˜æ€§èƒ½æ¶æ„**ï¼š
- Rust + Tokio å¼‚æ­¥å¹¶å‘åŸºç¡€
- é›¶æ‹·è´å’Œå†…å­˜æ˜ å°„ä¼˜åŒ–
- å¤šçº§ç¼“å­˜å’Œæ™ºèƒ½é¢„å–

**ğŸ›¡ï¸ å¯é æ€§ä¿éšœ**ï¼š
- äº‹åŠ¡æ€§çŠ¶æ€ç®¡ç†
- ä¼˜é›…é™çº§å’Œé”™è¯¯æ¢å¤
- åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ç†å¿µ

**ğŸ”§ å¯æ‰©å±•æ€§**ï¼š
- æ¨¡å—åŒ–å’Œæ’ä»¶åŒ–æ¶æ„
- æ ‡å‡†åŒ–æ¥å£å’Œåè®®
- é…ç½®é©±åŠ¨çš„çµæ´»æ€§

### ğŸš€ æŠ€æœ¯åˆ›æ–°

1. **æ™ºèƒ½é£æ§å¤„ç†ç³»ç»Ÿ** - ä¸šç•Œé¦–åˆ›çš„é›¶å¹²é¢„é£æ§å¤„ç†
2. **åŒé‡é‡ç½®æ¶æ„** - è‡ªåŠ¨åŒ–ä¸ç²¾ç¡®æ§åˆ¶çš„å®Œç¾ç»“åˆ
3. **åŠ¨æ€å¹¶å‘è°ƒåº¦** - åŸºäºæ€§èƒ½åé¦ˆçš„è‡ªé€‚åº”å¹¶å‘æ§åˆ¶
4. **å¤šçº§ç¼“å­˜ç³»ç»Ÿ** - å†…å­˜ã€ç£ç›˜ã€æ•°æ®åº“çš„ä¸‰çº§ç¼“å­˜æ¶æ„

è¿™å¥—æ¶æ„ä¸ä»…è§£å†³äº†å½“å‰çš„æŠ€æœ¯æŒ‘æˆ˜ï¼Œæ›´ä¸ºæœªæ¥çš„åŠŸèƒ½æ‰©å±•å’Œæ€§èƒ½ä¼˜åŒ–å¥ å®šäº†åšå®çš„åŸºç¡€ï¼Œä»£è¡¨äº† bili-sync ä»å·¥å…·å‘å¹³å°æ¼”è¿›çš„é‡è¦é‡Œç¨‹ç¢‘ã€‚